# 데이터 수집

## 데이터 수집

- 웹 스크레이핑(Web Scraping)
  - 하나의 특정 웹 페이지에서 원하는 정보를 받아오는 것
- 웹 크롤링(Web Crawling)
  - 컴퓨터가 자동으로 여러 웹 페이지를 수집하는 것

## 서버와 클라이언트

- 서버(Server)
  - 서비스를 제공하는 쪽
  - 클라이언트의 요청을 보고 필요한 것(HTML, CSS, JS등)들을 클라이언트에게 돌려줌(Response)
  - ex) 어딘가에 존재하는 컴퓨터

- 클라이언트(Client)
  - 서비스를 제공받는 쪽
  - 서버에게 Request를 보냄
  - ex) 웹 브라우저

## 웹사이트 주소 이해하기

- URL : https://www.ikea.com/catalog/news?sorting=price&pageNumber=4
  - `https` : **소통 방식**(http, https 등)
  - `www.ikea.com` : **도메인 이름**
  - `/catalog/news` : **경로** -> 나타낼 페이지
  - `?sorting=price&pageNumber=4` : **쿼리스트링(파라미터)** -> 페이지에 옵션들을 넘겨줌

- URL : https://en.wikipedia.org/wiki/Computer_programming#Debugging
  - `https` : 소통 방식
  - `en.wikipedia.org` : 도메인 이름
  - `/wiki/Computer_programming` : 경로
  - `#Debugging` : 위치 지정 -> 웹 페이지의 특정 부분(섹션)으로 이동. 실제 페이지의 내용이 변경되는 건 아님!